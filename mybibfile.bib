@article{lee2008importance,
	title={The importance of walking to public health},
	author={Lee, I-Min and Buchner, David M},
	journal={Medicine \& Science in Sports \& Exercise},
	volume={40},
	number={7},
	pages={S512--S518},
	year={2008},
	publisher={LWW}
}

@INPROCEEDINGS{anymal,
  author={Hutter, Marco and Gehring, Christian and Jud, Dominic and Lauber, Andreas and Bellicoso, C. Dario and Tsounis, Vassilios and Hwangbo, Jemin and Bodie, Karen and Fankhauser, Peter and Bloesch, Michael and Diethelm, Remo and Bachmann, Samuel and Melzer, Amir and Hoepflinger, Mark},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={ANYmal - a highly mobile and dynamic quadrupedal robot}, 
  year={2016},
  volume={},
  number={},
  pages={38-44},
  doi={10.1109/IROS.2016.7758092}
}

@INPROCEEDINGS{cheetah,
  author={Bledt, Gerardo and Powell, Matthew J. and Katz, Benjamin and Di Carlo, Jared and Wensing, Patrick M. and Kim, Sangbae},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot}, 
  year={2018},
  volume={},
  number={},
  pages={2245-2252},
  doi={10.1109/IROS.2018.8593885}}

@article{haarnoja2018learning,
  title={Learning to walk via deep reinforcement learning},
  author={Haarnoja, Tuomas and Ha, Sehoon and Zhou, Aurick and Tan, Jie and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.11103},
  year={2018}
}



% bipedal walking using deep reinforcement learning
@inproceedings{xie2018feedback,
	title={Feedback control for cassie with deep reinforcement learning},
	author={Xie, Zhaoming and Berseth, Glen and Clary, Patrick and Hurst, Jonathan and van de Panne, Michiel},
	booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	pages={1241--1246},
	year={2018},
	organization={IEEE}
}

@article{beranek2021behavior,
	title={A Behavior-Based Reinforcement Learning Approach to Control Walking Bipedal Robots Under Unknown Disturbances},
	author={Beranek, Richard and Karimi, Masoud and Ahmadi, Mojtaba},
	journal={IEEE/ASME Transactions on Mechatronics},
	year={2021},
	publisher={IEEE}
}

@inproceedings{vaghei2014actor,
	title={Actor-critic neural network reinforcement learning for walking control of a 5-link bipedal robot},
	author={Vaghei, Yasaman and Ghanbari, Ahmad and Noorani, Sayyed Mohammad Reza Sayyed},
	booktitle={2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM)},
	pages={773--778},
	year={2014},
	organization={IEEE}
}

@inproceedings{jiang2020motion,
	title={Motion Sequence Learning for Robot Walking Based on Pose optimization},
	author={Jiang, Yancao and Zhang, Weiyi and Farrukh, Fasih Ud Din and Xie, Xiang and Zhang, Chun},
	booktitle={2020 IEEE International Conference on Mechatronics and Automation (ICMA)},
	pages={1877--1882},
	year={2020},
	organization={IEEE}
}

% reinforcement learning theory
@book{sutton2018reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

% reinforcement learning in robotic applications
@article{kober2013reinforcement,
	title={Reinforcement learning in robotics: A survey},
	author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
	journal={The International Journal of Robotics Research},
	volume={32},
	number={11},
	pages={1238--1274},
	year={2013},
	publisher={SAGE Publications Sage UK: London, England}
}
@article{kormushev2013reinforcement,
	title={Reinforcement learning in robotics: Applications and real-world challenges},
	author={Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G},
	journal={Robotics},
	volume={2},
	number={3},
	pages={122--148},
	year={2013},
	publisher={Multidisciplinary Digital Publishing Institute}
}

% proximal policy optimization (PPO): formulation
@article{schulman2017proximal,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}

% proximal policy optimization: applications
@inproceedings{melo2019learning,
	title={Learning humanoid robot running skills through proximal policy optimization},
	author={Melo, Luckeciano Carvalho and M{\'a}ximo, Marcos Ricardo Omena Albuquerque},
	booktitle={2019 Latin american robotics symposium (LARS), 2019 Brazilian symposium on robotics (SBR) and 2019 workshop on robotics in education (WRE)},
	pages={37--42},
	year={2019},
	organization={IEEE}
}

@inproceedings{bohn2019deep,
	title={Deep reinforcement learning attitude control of fixed-wing uavs using proximal policy optimization},
	author={B{\o}hn, Eivind and Coates, Erlend M and Moe, Signe and Johansen, Tor Ame},
	booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)},
	pages={523--533},
	year={2019},
	organization={IEEE}
}

@inproceedings{kristensen2020strategies,
	title={Strategies for using proximal policy optimization in mobile puzzle games},
	author={Kristensen, Jeppe Theiss and Burelli, Paolo},
	booktitle={International conference on the foundations of digital games},
	pages={1--10},
	year={2020}
}

% sthocastic policies
@inproceedings{tedrake2004stochastic,
	title={Stochastic policy gradient reinforcement learning on a simple 3D biped},
	author={Tedrake, Russ and Zhang, Teresa Weirui and Seung, H Sebastian},
	booktitle={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)(IEEE Cat. No. 04CH37566)},
	volume={3},
	pages={2849--2854},
	year={2004},
	organization={IEEE}
}

% deep reinforcement learning
@inproceedings{henderson2018deep,
	title={Deep reinforcement learning that matters},
	author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
	booktitle={Proceedings of the AAAI conference on artificial intelligence},
	volume={32},
	number={1},
	year={2018}
}

@article{li2017deep,
	title={Deep reinforcement learning: An overview},
	author={Li, Yuxi},
	journal={arXiv preprint arXiv:1701.07274},
	year={2017}
}